[["dataSense-book.html", "What Do the Data Say? — Traps to Avoid Examples that inform and educate Preface Chapter 1 Systems of human judgment 1.1 System 1 and System 2 — further comments 1.2 The Intuition of Professionals 1.3 A demand for discipline &amp; careful thought 1.4 Further examples 1.5 Misbehaving humans! 1.6 Negotiating Life in an Uncertain World1 Chapter 2 Effective use of graphs 2.1 General principles 2.2 Varying time intervals — show rates, not counts 2.3 Banking — the importance of aspect ratio 2.4 Scales that show changes by equal factors 2.5 Different graphs serve different purposes 2.6 Helpful web links are: Chapter 3 Selection and survivor bias 3.1 The hazards of convenience samples 3.2 UK cotton worker wages in the 1880s 3.3 The uneasy path from hindsight to insight 3.4 The message in the missing bullet holes Chapter 4 Medicine and health 4.1 Useful sources of advice and information 4.2 PSA Screening for Prostate Cancer, &amp; more 4.3 Randomized Controlled Trials (RCTs) versus Population Studies 4.4 Avoid, or expose infants to peanuts? 4.5 False Positives 4.6 The effectiveness of surgery Chapter 5 Mistakes (and worse) that matter 5.1 [The MMR vaccine scandal]( 5.2 Sally Clark’s disturbing cot death story 5.3 The Reinhoff and Rogoff saga 5.4 What do malaria drugs do to Covid-19 patients?4 5.5 A simplistic use of publicly available data Chapter 6 Weighting effects that skew statistics 6.1 Covid-19 deaths — comparing countries 6.2 A paradox of human intuition 6.3 Further examples of the same type 6.4 Cricket Bowling Averages 6.5 Epistatic effects on genetic studies Chapter 7 Regression and Correlation 7.1 What direction does the correlation go? 7.2 Regression to the mean 7.3 Regression to the mean in a variety of contexts 7.4 Moderating subjective assessments 7.5 Some further comments on regression to the mean Chapter 8 The uses and limits of observational data 8.1 We have a prediction. What are the drivers? 8.2 Time per unit distance for hillraces 8.3 By air, or by water — 1849 cholera deaths 8.4 John Snow documents a natural experiment 8.5 Are there missing explanatory factors? 8.6 The uses and traps of “algorithmic” methods 8.7 Examples that illustrate other traps 8.8 Global mean temperature trends Chapter 9 Critiquing scientific claims 9.1 What results can be trusted? 9.2 The case of Eysenck and his collaborators 9.3 Detection of Covid-19 from chest images 9.4 Laboratory studies — what do we find? 9.5 Truths that special interests find inconvenient 9.6 Tricks used to dismiss established results Chapter 10 Notes 1. The Jung et al. (2014) US hurricane data Further reading — books, videos, and websites References About the Author", " What Do the Data Say? — Traps to Avoid Examples that inform and educate John Maindonald 2021-08-12 Preface Placeholder Chapter 1 Systems of human judgment Placeholder 1.1 System 1 and System 2 — further comments 1.2 The Intuition of Professionals Obstacles to effective judgment 1.3 A demand for discipline &amp; careful thought 1.4 Further examples A simple (and, arguably, trick) example Even careful critics sometimes get it wrong Think again — a very simple example 1.5 Misbehaving humans! 1.6 Negotiating Life in an Uncertain World1 Chapter 2 Effective use of graphs Placeholder 2.1 General principles 2.2 Varying time intervals — show rates, not counts 2.3 Banking — the importance of aspect ratio 2.4 Scales that show changes by equal factors 2.5 Different graphs serve different purposes Relative distance scales 2.6 Helpful web links are: Chapter 3 Selection and survivor bias Placeholder 3.1 The hazards of convenience samples Convenience samples sometimes have a story to tell 3.2 UK cotton worker wages in the 1880s 3.3 The uneasy path from hindsight to insight Tales of standout past success 3.4 The message in the missing bullet holes Chapter 4 Medicine and health Placeholder 4.1 Useful sources of advice and information The Harding Center for Risk Literacy Harding Center Medical Fact Boxes The Cochrane Center2 Winton Centre for Risk and Evidence Communication3 4.2 PSA Screening for Prostate Cancer, &amp; more Breast cancer screening — a contested area 4.3 Randomized Controlled Trials (RCTs) versus Population Studies Randomized Controlled Trials — the gold standard? A note in passing: HiPPO decisions vs A/B testing Population studies — groups must be broadly comparable Issues for all types of study 4.4 Avoid, or expose infants to peanuts? 4.5 False Positives The Aspirin story (randomized trials) 4.6 The effectiveness of surgery Chapter 5 Mistakes (and worse) that matter Placeholder 5.1 [The MMR vaccine scandal]( 5.2 Sally Clark’s disturbing cot death story 5.3 The Reinhoff and Rogoff saga Is there a pattern across countries? There are further serious issues of interpretation Parting comments 5.4 What do malaria drugs do to Covid-19 patients?4 5.5 A simplistic use of publicly available data Chapter 6 Weighting effects that skew statistics Placeholder 6.1 Covid-19 deaths — comparing countries 6.2 A paradox of human intuition UCB Admissions Data – Another perspective A note on Lord’s paradox 6.3 Further examples of the same type Does Baclofen help in reducing pain? Web page revenue per click 6.4 Cricket Bowling Averages Runs (R), wickets (W) and runs per wicket ({}) Fair comparison: Compare runs per wicket ({}) 6.5 Epistatic effects on genetic studies Chapter 7 Regression and Correlation Placeholder 7.1 What direction does the correlation go? 7.2 Regression to the mean 7.3 Regression to the mean in a variety of contexts Decathlon scores — between event correlations Total profit to total income ratio, by industry class NBA player total points — correlations decline over time The Sports Illustrated cover “jinx” Secrist’s “The Triumph of Mediocrity in Business” “Do old fallacies ever die?” 7.4 Moderating subjective assessments Forecasting sales 7.5 Some further comments on regression to the mean Choosing from job applicants Kahneman’s comments on regression to the mean Regression to the mean in verse Chapter 8 The uses and limits of observational data At least in principle, it is relatively straightforward to use regression type methods to make predictions for a set of new data that have been sampled in the same way. What is hard for observational data, harder than is commonly acknowledged, is to give the model coefficients a causal interpretation. For this, it is necessary to have a clear understanding of the processes involved. There will be several, perhaps a very large number, of explanatory variables, and an outcome variable. The aim is to find a model that will make predictions for new data. Note the predictive/descriptive distinction. Note the “in sample/out of sample” distinction. But is the “new” a random sample of the old population? (Is the ‘target’ a random sample of the ‘source?’) There are insightful comments at: https://mathbabe.org/2011/06/16/the-basics-of-quantitative-modeling/ 8.1 We have a prediction. What are the drivers? The issues that arise for observational studies do not in general have clear and easy answers. The discussion on Andrew Gelman’s blog5 canvasses some of the more important issues. There are no simple answers! Where there are several explanatory variables, and the aim is to determine the manner in which they may be driving predictions, matters get much more complicated. Thus, in a comparison between two groups (in the example that follows, midwife led versus medical led neonatal care) one variable or factor may be of particular interest, while other variables are used to adjust for differences between the two groups that are at most a secondary focus of interest. Variables that are of secondary interest are commonly referred to as covariates. Regression coefficients can be misleading guides to what is driving predictions if one or more of the relevant covariates is not available or is not properly accounted for. A paradox of the Yule-Simpson type, sometimes referred to as Laird’s paradox, has the same potential to deceive, a potential that should be ignored. Little that has been published since Rosenbaum (2002) clarifies greatly the advice that can be given for practical data analysis, beyond what Rosenbaum has to say. Note, however, that Pearl and Mackenzie (2018) would dispute this assessment. Pearl and his co-author do a good job of highlighting important issues that should be addressed in order to make causality judgments, at the same time overplaying what their methodology can in general achieve. If strictly implemented, the standards are so high that they severely limit what they can in practice achieve. Causality diagrams have a central role. There is a detailed, and insightful, discussion of the history that finally led to the conclusion that smoking causes lung cancer. 8.2 Time per unit distance for hillraces The DAAG:nihills dataset has record times for 23 Northern Ireland Mountain Running Association hillraces, as given in the 2007 calendar. In the models fitted and graphs shown that follow, the distance measure is Dist (distance converted to kilometers), the climb measure is Climb (vertical distance between lowest and highest point, in meters), and the time measure is Time (in minutes). How does time per unit distance (timePerKm) vary with distance. We will fit two equations, both with \\(y\\) = timePerKm. Figure ??A gives a visual represention of the way that timePerKm depends on log(Dist), when log(Climb) is held at its mean value. Use of log(Dist) rather than Dist means that we are looking at the effect of relative, rather than absolute changes. Thus, distance on the \\(x\\)-axis from 2 to 4 (km) is the same as the distance from 4 to 8, or from 8 to 16, or from 16 to 32. The equation that is plotted is timePerKm = 8.45 -1.6 \\(\\times\\) log(Dist) Figure ??B gives a visual represention of the way that timePerKm depends on log(Dist), when log(Climb/Dist) is held at its mean value. The equation that is plotted is timePerKm = 3.33 + 0.84 \\(\\times\\) log(Climb/Dist) Figure 8.1: Variation in time per unit distance with distance. Panel A shows the pattern of change when log(Climb) is held constant at its mean value, while Panel B shows the pattern of change when log(Climb/Dist) is held constant at its mean value. In Panel A, time per kilometer decreases quite sharply as distance increases. This happens because the ratio of Climb to Dist decreases if Climb is held constant while Dist increases, i.e., longer distance races involve gentler ascents and descents. Panel B shows what happens when Climb/Dist is held constant, i.e., we are comparing races with the same ratio of Climb to Dist. As expected, time per kilometer does then decrease as distance increases. The point of this example is to emphasize that the regression coefficients may differ greatly depending on what adjustments are made for other variables. This is important for attaching meaning to a coefficient. 8.3 By air, or by water — 1849 cholera deaths Farr, who worked as statistician in the UK Registrar General’s  office, collected data on deaths from cholera in London in the 1849 epidemic. The prevailing theory at the time was that  miasma, or bad air created from rotting matter, was responsible for transmitting diseases. Farr classified districts into three groups thus, according to the source of the water for most of the householders: 1) Thames between Battersea Bridge and Waterloo Bridge, coded as Battersea; 2) New River/Rivers Lea and Ravensbourne (sources away from the Thames), coded as NewRiver; 3) Thames between Kew and Hammersmith, i.e., further up the Thames than the first group, where the water was less polluted by sewage, coded as Kew. Figure 8.2 summarizes results from a regression analysis that used Farr’s data Figure 8.2: Each panel shows, in turn, the estimated contribution of a term in the model relative to the mean contribution from other model terms. Changes in deaths are on a log scale, so that an increase by one unit multiplies the odds of death by close to 2.7, around an overall mean of just over six per 1000. None of the terms stands out as substantially more important than any other. Higher rates for the poor, where crowded conditions would commonly make it difficult to maintain hygiene, were to be expected. Snow (1855) argued that those living close to the Thames, and especially in the South, were more likely to be getting their water from or via sources that were likely to be contaminated with human excreta. The piping of water up to higher ground gave contaminants more time to settle, with less chance of exposure to human excreta. He gave examples that he had observed directly, where the likely means of transmission of the infection appeared to be via a water source, or from poor hygiene. Farr gave Snow’s arguments some credibility, but discussed ways that the air might be the main source of transmission of an organism responsible for the disease, which multiplied in a process akin to fermentation that was presumed to take place in putrefying matter. A context has to be provided in which to interpret the data and the regression results. While Snow had a better understanding of the contextual information, it was not comprehensive enough to persuade other medical specialists. Data from the 1854 epidemic, where it was possible to compare deaths supplied from a company that continued to get its supply from lower highly polluted Thames water with that from the company that had moved its supply higher up to less polluted water, seems in retrospect to clinch the issue. The perspective brought by germ theory would come later, with the work of Pasteur in the late 1850s and Koch in the 1880s. 8.4 John Snow documents a natural experiment Events that led up to the 1849 cholera deaths and that followed, were6 6,500 died from cholera in London in 1832 Medical opinion blamed “miasma,” or noxious air (Stink from rotting garbage, faeces, &amp; pollution in Thames) Poor areas had more cholera – worst smell, sanitation (But, also, people were older, houses poorly heated, …) Cesspits – night-soil periodically taken away 1842:Edwin Chadwick, in The Sanitary Conditions of the Labouring Population (1842)7 showed a direct link between poor living conditions, disease and life expectancy Like others who accepted the “miasma” theory of disease, Chadwick did not understand that cholera, along with some other major diseases, were water-borne. 1848: the Nuisances Removal and Diseases Prevention Act (Gazette issue 20637) was passed with the aim of stopping the 1848-9 epidemic. The suggestion was to effectively dump the contents of cesspools and raw sewage pits into the Thames, which was London’s main source of drinking water. This only served to exacerbate the problem. 1848-49 epidemic followed shortly after the cesspits were banned Both water companies — Lambeth, and Southwark and Vauxhall, were taking water from the same polluted source. Death rates were high for both companies 1850: Arthur Hassall’s careful microbiological study: “… a portion of the inhabitants are made to consume … a portion of their own excrement, and … to pay for the privilege” (Hassall 1850) The 1854 epidemic — a natural experiment The 1852 act required water supply companies to move water intake upriver by 1855. By the time of the 1854 epidemic, Lambeth had moved the intake 22 miles upriver, where the water was not contaminated by London sewage. The Southwark and Vauxhall intake was unchanged until 1855. Data on the distribution of cholera in the 1854 epidemic then allowed Snow to test the claims made in his 1849 study. Lambeth versus Southwark &amp; Vauxhall “The experiment, too, was on the grandest scale. No fewer than 300,000 people …, from gentlefolks down to the very poor, were divided into two groups without their choice, and, in most cases, without their knowledge; one group being supplied with water containing the sewage of London, and, amongst it, whatever might have come from the cholera patients, the other group having water quite free from such impurity.” Use water from the brewery, and stay healthy! Snow noted that “Within 250 yards of the spot where Cambridge Street joins Broad Street there were upwards of 500 fatal attacks of cholera in 10 days….” By contrast, none of the employees of a local Soho brewery developed cholera. Figure 8.3: Deaths (red dots) and pump locations. Polygons that surround each pump enclose the locations for which that is the nearest pump. The reason, he judged, was that they drank water from the brewery (which had a different source from the Broad St pump) or just drank beer alone. Coleman (2019) gives detailed comments on Snow’s work. It took a further ten years for the medical establishment to begin to accept Snow’s conclusions. Similar issues, arising from failures to ensure proper drainage systems, were repeated, from the 1840s and 1850s through until the end of the century, in New Zealand cities.8 8.5 Are there missing explanatory factors? The (Wernham et al. 2016) study used data from 244,047 singleton term deliveries that occurred between 2008 and 2012 to make the claim that midwife led care, as opposed to medical led care, gave a greater risk of adverse fetal and neonatal outcomes. Notably, the claim was that midwife led care resulted in a lower Apgar score (a measure of infant health immediately after birth) and a greater risk of the imprecisely defined diagnosis of birth asphyxia. This study was then the basis for exaggerated claims in an article in the October 8-14 2016 issue of the NZ Listener (Chisholm 2016 “Birth Control”). Contrary to what was claimed, the research did not “lob a grenade into the historically war-torn territory of New Zealand’s maternity care.” Even less did its results warrant the melodramatic claims of “Alarming maternity research” and “Revolution gone wrong” that appeared on the Listener’s front cover. A major issue with the analysis is that it relies on using the NZ Deprivation Index9 to adjust for socioeconomic differences. This provides a deprivation score for meshblocks, each of around 60–110 people. It estimates the relative socioeconomic deprivation of an area, and does not directly relate to individuals. Deprived areas will often include some individuals with high socioeconomic status. Caesarean section, as a delivery type, may well have been more accessible for those of higher socioeconomic status. For National Women’s in Auckland, the elective Caesarean rate at term over 2006-2015 for doctor-led care was 32.8%, as against 7.4% for self employed midwives (Farquhar, McCowan, and Fleming 2016). Effects from fetal alcohol syndrome were not accounted for, nor were direct effects from substance abuse. According to NZ Ministry of Health information, international data indicates that fetal alcohol syndrome may affect as many as 3% of births.10 Studies that are similarly relatively carefully done, but naive in the weight placed on the regression results, are embarrassingly common. There are analysis tools, and associated graphs, that the authors of the study could and should have used to shed light on the likely effectiveness of the adjustments made for differences between the two groups, other than whether the delivery was midwife led or medical led. 8.6 The uses and traps of “algorithmic” methods Decision tree approaches offer a way to use data that includes both spam and legitimate email messages to screen out spam as new messages appear. In practical use, such datasets have to be continually updated, as spammers change their strategies. For illustrative purposes, we will work with a dataset that is long past its “use by” date. Figure 8.4 shows the distributions of values of what were judged relevant variables. Figure 8.4: Boxplots, showing distribution of variable values in data used to predict email spam Figure 8.5 shows a decision tree that has been derived for the spam data. This would be too inaccurate for practical use, but it is easy to see how it might be used, and is useful as a lead in to discussing random forests. Figure 8.5: Decision tree for spam data. If the condition is satisfied, take the branch to the left. Otherwise, take the branch to the right. From trees to forests “Random forests” improve on decision trees by using samples from the data to create a forest (a “random forest”) of trees, then voting between the trees. A downside is that “Random forests” and similar methods operate largely as black boxes. Random forest type methods may work well when the way that explanatory factors conspire to give an output is unclear. What works, but one does not know why, may be effective for present circumstances. This can be both a trap and a virtue. Thus, for detecting spam: When it fails, we will likely have few clues why! This may, for a short time, impede spammers! Spammers are anyway continually refining their strategies Spam detectors must be responsive to new challenges Automated systems that can be easily gamed abound. They are a menace! It helps to know the how and why of the algorithms used Cathy O’Neill: “… it’s not enough to just know how to run a black box algorithm. You actually need to know how and why it works, so that when it does’nt work, you can adjust.” 8.7 Examples that illustrate other traps Are herricanes more dangerous than himmicanes? Figure 8.6: Deaths versus damage estimate in US dollars. The red (for female) and blue (for male) dashed lines are close equivalents of Jung at al’s fit to the data. The \\(y\\)-axis uses a scale of equal relative numbers of deaths, while the \\(x\\)-axis uses a scale of equal dollar damage costs. The United States National Hurricane Center began formally naming hurricanes in 1950, a task now under control of the World Meteorological Organization. Female names were used for Atlantic hurricanes from 1953 to 1978, with a mix of male and female names used from 1979 onwards. Authors of a paper titled “Female hurricanes are deadlier than male hurricanes” (Jung et al. 2014) compared death rates from named Atlantic hurricanes with female names with death rates for those given male names, for 94 Atlantic hurricanes that made landfall in the United States during 1950-2012. The suggestion was that authorities took the risk from hurricanes with female names less seriously. The paper attracted wide interest on the blogosphere, with female hurricanes jokingly called herricanes and males called himmicanes. The separate dotted lines in Figure 8.6, red for female and blue for male, are a close equivalent to the authors’ fit to the data. Notice the use of a relative (numbers of deaths) scale on the \\(y\\)-axis, and a dollar scale on the \\(x\\)-axis. Why did the authors not use, at least as a starting point, the same relative scale on both axes, as in Figure 8.7? An unfortunate consequence of the use of a linear dollar scale on the \\(x\\)-axis is that the slopes of the lines are strongly influenced by the final four points at the upper end of the scale. Figure 8.7: Deaths versus damage estimate in US dollars, with logarithmic scales on both axes. Separate fitted lines for male and female hurricanes cannot be distinguished. Jung et al used a logarithmic scale on the vertical axis only, which on this graph leads to the dashed curves. As well as using a relative scale on the \\(x\\)-axis, Figure 8.7 has used a methodology that allows the data to determine the form of the response. Deaths do on average increase more at a higher rate than the damage measure, but not at the rate suggested by the dashed curves, and there is now no evident difference between the two curves. Figures 8.6 and 8.7 include data for the hurricanes Audrey (in 1957) and Katrina (in 2005), which Jung et al omitted as outliers. Other differences between the Jung et al analysis, and the analyses reflected in Figures 8.6 and 8.7 are documented in Note 1 Historical speed of light estimates — is there a pattern? Figure 8.8: Successive speed of light estimates. Error estimates are available for the 1855 and later measurments. Panel B limits attention to measurements made in 1926 and later. The line was fitted with no adjustment for the very different error estimates. The dashed curve, which incorporates such adjustments, is statistically indistinguishable from the thick gray horizontal line. Creationist Barry Setterfield has argued that a reduction over time in the speed of light has led the passage of time to slow down, relative to the remote past, so that the universe is thousands rather than billions of years old. His arguments rely on making various adjustments to figures obtained historically, selecting what he regarded as the most reliable data, and then fitting a curve. He tells a story that is very different from that of Panel A of Figure 8.8. For the measurements from 1862 onward, estimates of accuracy are available. Until 1950, each new estimate lay outside the bounds for the previous estimate, indicating that these were underestimates. Even if one were to accept Setterfield’s manipulation of the data, it makes no sense at all to fit either lines such as are shown, or curves, to data values which have such very different accuracies. The right panel is limited to the points from 1926 and on, marked off with the gray background on the left panel.11 Even if one were to accept Setterfield’s manipulation of the data, it makes no sense at all to fit either lines such as are shown, or curves, to data values which have such very different accuracies as those shown in the graphs. For the measurements from 1862 onwards, estimates of accuracy are available. Until 1950, each new estimate lay outside the bounds for the previous estimate, indicating that these were underestimates. The right panel is limited to the points from 1926 and on, marked off with the gray background on the left panel. 8.8 Global mean temperature trends Figure 8.9: Anomalies (differences) in hundredths of a degree centigrade from global average temperatures over 1951-1980, plotted against year. The gray curve shows, for each year, the average anomaly up to that point in time. The last year in which this lay below the gray line was 1962. Figure 8.9 plots global air and sea surface temperature anomaly data against year. Anomalies, in hundredths of a degree centigrade, are differences from the 1951-1980 global average. The grey curve plots the average anomaly up to that point in time. Observe that 1964 was the last year in which the global temperature fell below the average to that time. For the 52 subsequent years (from 1965 to 2016 inclusive), the global average was above the average up to that date. Under the (false) assumption that global temperature is varying randomly (and therefore independently) about a common mean, the probability of this happening is 2\\(^{-40}\\) = 9.1 \\(\\times\\) 10\\(^{-13}\\). A variation of this argument came from a speaker on the Australian ABC Science Show on April 3 2011. Under any model that accounts for what are now fairly well understood patterns of correlation over time, the probability, while very small, is not that small! Arguments that overstate the case for what is now a well-established pattern of change are unhelpful It is likewise nonsensical to fit a line to the cherry-picked years 1998-2008, where the trend was relatively flat. Chapter 9 Critiquing scientific claims Placeholder 9.1 What results can be trusted? Sources of failure 9.2 The case of Eysenck and his collaborators 9.3 Detection of Covid-19 from chest images 9.4 Laboratory studies — what do we find? The Reproducibility: Psychology project 9.5 Truths that special interests find inconvenient Styles of argument Big Pharma — inconvenient data What can one trust? 9.6 Tricks used to dismiss established results Chapter 10 Notes Placeholder 1. The Jung et al. (2014) US hurricane data Further reading — books, videos, and websites The books noted have all been referred to in the text. Kahneman (2013) . Thinking, fast and slow. Interview with Kahneman12 A brief animated overview of some key points13 Smith (2014) . Standard Deviations: Flawed Assumptions, Tortured Data, and Other Ways to Lie with Statistics Brian Lehrer interview with Smith14 Ellenberg (2015) . How not to be wrong. There are links to several Ellenberg video clips15 Levitin (2016) . A field guide to lies and statistics. Nisbett (2016) . Tools for smart thinking. Cairo (2013) . The functional art: an introduction to information graphics and visualization. Ritchie (2020) . Science fictions: Exposing fraud, bias, negligence and hype in science. BBC links to helpful web resources16 References "]]
